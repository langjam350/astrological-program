{
  "enabled": true,
  "endpoint": "http://localhost:11434/api/generate",
  "model": "llama3.1:latest",
  "timeout": 900,
  "max_tokens": 1000,
  "temperature": 0.7
}